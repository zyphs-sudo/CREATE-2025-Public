# AI Ethics Case Studies

The following are some scenarios where AI in used in an academic and professional 
setting in engineering. Please read these case studies carefully and discuss among 
your groups the ethical dilemma associated with each situations. If you need some 
assistance, think about some answers to the prompts provided under each scenarios. 
You are not limited to these questions, and are encouraged to think beyond them. 

## Case Study 1: The Invisible Coder

Sarah is part of a team working on a final project for a coding class. The professor allows use of AI tools, but says students must understand everything they submit. 
Sarah uses ChatGPT to generate most of the Flask routes and Firebase integration. 
She copies and pastes large portions into the project, tweaking only a few lines. 
The rest of the team doesn’t know how the backend was written. When asked how the 
app works during the demo, Sarah stumbles over the explanation.

### Questions to consider: 
. Is Sarah’s use of ChatGPT ethical? Why or why not?
. Did she have a responsibility to explain her code to her teammates?
. What should the team do in the future?

## Case Study 2: The Off-Policy Assistant

James just started his first internship at a tech company. The company has its 
own internal chatbot trained on company documentation, and employees are 
expected to use it for help. James tries it, but finds the bot confusing and 
outdated. Instead, he secretly uses ChatGPT to complete a key task more quickly. 
His solution works well and impresses his manager—but he’s unsure if he did 
the right thing.

### Questions to consider: 
. Is James's use of ChatGPT ethical? Should James have stuck with the company 
chatbot, even if it was less helpful?
. Is it wrong to use outside AI tools at work without asking? Why and why not? 
. Should companies be more flexible about tool choice? What could be the 
implications of using ChatGPT over company tools and vice versa?

## Case Study 3: AI Resume Screener

A university career platform introduces a new AI-powered resume screener to recommend students for co-op placements. Within a few weeks, a pattern emerges: students with international-sounding names or non-traditional extracurriculars seem to be getting fewer interviews. Some students suspect the AI is biased based on training data, but the company says the system is working “as designed.”

### Questions to consider: 
. Is the use of AI in this scenario ethical? Why and why not? 
. How can bias enter AI systems like resume filters?
. Who is responsible when an algorithm makes unfair decisions?
. What can be done to improve this situation? 

## Case Study 4: The Autopilot Student

In an intro programming course, the professor tells students that they can use ChatGPT to assist with assignments—but only if they understand and can explain the code. Alex uses ChatGPT to complete every task in the course. He gets full marks, but when asked in a peer review to explain how his program works, he says, “Honestly, I don’t really know. ChatGPT just did it.”

### Questions to Consider: 
. Did Alex follow the rules set by the course? Is his use of AI considered to be an academic misconduct? Why or why not? 
. What are the risks of using AI like this?
. Should students be allowed to use AI in their course work? Why and why not?

Discuss these case studies and the ethics behind each of them in your group. You will be asked to share your findings with the class. 